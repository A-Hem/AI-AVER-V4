import argparse
import json
import sys
from pathlib import Path

import numpy as np
import torch
import torchvision.transforms as transforms

# Add src to path and import our new utility function and the model
sys.path.append(str(Path(__file__).parent))
from model import PRNUModel
from utils import calculate_sha256

def load_model(model_path: str, device: torch.device) -> PRNUModel:
    """Loads the trained PRNUModel from a checkpoint."""
    model = PRNUModel()
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    model.eval()
    print(f"Model loaded from {model_path} (Epoch: {checkpoint['epoch']}, EER: {checkpoint['eer']:.2f}%)")
    return model

def load_and_verify_pattern(pattern_path: Path, manifest: dict) -> np.ndarray:
    """
    Loads a noise pattern and verifies its integrity against the manifest.
    
    This is a critical security step. It ensures that the data being processed
    is exactly the data that was generated by the audited preprocessing script.
    
    Args:
        pattern_path: Path to the .npy noise pattern file.
        manifest: The loaded _manifest.json from the preprocessing run.
        
    Returns:
        The loaded numpy array if verification passes.
        
    Raises:
        ValueError: If verification fails.
    """
    print(f"Verifying {pattern_path}...")
    
    # 1. Calculate the hash of the current file on disk.
    current_hash = calculate_sha256(pattern_path)
    
    # 2. Find the corresponding record in the manifest.
    record_found = None
    for record in manifest['processed_files']:
        # Use Path objects to normalize paths for reliable comparison
        if Path(record['output_path']).resolve() == pattern_path.resolve():
            record_found = record
            break
            
    if not record_found:
        raise ValueError(f"Verification failed: No record for {pattern_path} found in the manifest.")
        
    # 3. Compare the hashes.
    manifest_hash = record_found.get('output_sha256')
    if not manifest_hash:
        raise ValueError(f"Verification failed: Record for {pattern_path} in manifest has no hash.")

    if current_hash != manifest_hash:
        raise ValueError(f"Verification FAILED: Hash mismatch for {pattern_path}.\n"
                         f"  - On-disk hash: {current_hash}\n"
                         f"  - Manifest hash: {manifest_hash}\n"
                         "  - The file may have been tampered with.")
                         
    print(f"Verification successful for {pattern_path}.")
    
    # 4. Load and return the data.
    return np.load(pattern_path)

def prepare_tensor(pattern: np.ndarray, transform: transforms.Compose, device: torch.device) -> torch.Tensor:
    """
    Prepares the loaded noise pattern for the model.
    """
    # Convert numpy array to a PIL-like format (H, W, C) and then to tensor
    # The model expects a 3-channel input, so we stack the 1-channel noise pattern
    pattern_3channel = np.stack([pattern] * 3, axis=-1)
    
    # Apply the same transforms used during training (resize, ToTensor, normalize)
    tensor = transform(pattern_3channel).unsqueeze(0)
    
    return tensor.to(device)

def main():
    """Main refactored inference function with verification."""
    parser = argparse.ArgumentParser(
        description="Compare two preprocessed PRNU patterns with manifest verification.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("--model_path", type=str, required=True, help="Path to the saved model checkpoint.")
    parser.add_argument("--manifest_path", type=str, required=True, help="Path to the _manifest.json from the preprocessing run.")
    parser.add_argument("--pattern1_path", type=str, required=True, help="Path to the first .npy noise pattern.")
    parser.add_argument("--pattern2_path", type=str, required=True, help="Path to the second .npy noise pattern.")
    
    args = parser.parse_args()
    
    # --- File Validation ---
    model_path = Path(args.model_path).resolve()
    manifest_path = Path(args.manifest_path).resolve()
    pattern1_path = Path(args.pattern1_path).resolve()
    pattern2_path = Path(args.pattern2_path).resolve()
    
    for p in [model_path, manifest_path, pattern1_path, pattern2_path]:
        if not p.exists():
            print(f"Error: Input file not found: {p}", file=sys.stderr)
            sys.exit(1)

    # --- Main Execution ---
    try:
        # Load manifest
        print(f"Loading manifest from {manifest_path}")
        with open(manifest_path, 'r') as f:
            manifest = json.load(f)
            
        # Verify and load patterns
        pattern1 = load_and_verify_pattern(pattern1_path, manifest)
        pattern2 = load_and_verify_pattern(pattern2_path, manifest)

        # Configure device and model
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"\nUsing device: {device}")
        model = load_model(str(model_path), device)
        
        # Define transforms. These must match the training transforms.
        # NOTE: Applying ImageNet normalization to noise patterns is a point for
        # future refinement. For now, we maintain consistency with the trained model.
        transform = transforms.Compose([
            transforms.ToTensor(), # Converts numpy array (H,W,C) in range [0,255] to (C,H,W) in range [0,1]
            transforms.Resize((224, 224)), # Resize after converting to tensor
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])

        # Prepare tensors for the model
        tensor1 = prepare_tensor(pattern1, transform, device)
        tensor2 = prepare_tensor(pattern2, transform, device)
        
        # Perform inference
        with torch.no_grad():
            similarity, _, _ = model(tensor1, tensor2)
            similarity_score = similarity.item()

        # --- Generate Formal Result ---
        result = {
            "status": "success",
            "similarity_score": round(similarity_score, 6),
            "inputs": [
                {"path": str(pattern1_path), "verified_sha256": calculate_sha256(pattern1_path)},
                {"path": str(pattern2_path), "verified_sha256": calculate_sha256(pattern2_path)},
            ],
            "model": {
                "path": str(model_path),
                "verified_sha256": calculate_sha256(model_path)
            },
            "manifest": {
                "path": str(manifest_path),
                "verified_sha256": calculate_sha256(manifest_path)
            }
        }
        
        print("\n" + "="*60)
        print("FORENSIC INFERENCE RESULTS")
        print("="*60)
        print(json.dumps(result, indent=4))
        print("="*60)

    except (ValueError, Exception) as e:
        print(f"\n--- INFERENCE FAILED ---", file=sys.stderr)
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main()

